import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import io

# --- ç¶²é æ¨™é¡Œèˆ‡ä»‹ç´¹ ---
st.set_page_config(page_title="å°è‚¡ ETF ç¸¾æ•ˆåˆ†æå·¥å…·", layout="wide")
st.title("ğŸ“Š å°è‚¡ ETF è‡ªå‹•ç¯©é¸èˆ‡åˆ†æ")
st.write("æœ¬å·¥å…·æœƒè‡ªå‹•æŠ“å– HiStock çš„ ETF æ¸…å–®ï¼Œéæ¿¾æ‰æ§“æ¡¿ã€åå‘èˆ‡ä¸­åœ‹å¸‚å ´ ETFï¼Œä¸¦è¨ˆç®—è¿‘ä¸€å­£ã€åŠå¹´åŠä¸€å¹´çš„ç¶œåˆå ±é…¬ç‡ã€‚")

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# --- åŠŸèƒ½ 1ï¼šæŠ“å–æ¸…å–® ---
def get_etf_list():
    url = "https://histock.tw/stock/etf.aspx"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        etf_codes = []
        rows = soup.find_all('tr')
        china_keywords = ['ä¸­åœ‹', 'ä¸Šè­‰', 'æ»¬', 'æ·±', 'æ’ç”Ÿ', 'A50', 'é¦™æ¸¯', 'æ¸¯è‚¡']

        for row in rows:
            link = row.find('a', href=True)
            if not link or '/stock/' not in link['href']:
                continue
            href_code = link['href'].split('/')[-1]
            row_text = row.text.strip().replace('\n', ' ')

            if len(href_code) < 4 or len(href_code) > 6 or not href_code[0].isdigit():
                continue
            
            upper_code = href_code.upper()
            if upper_code.endswith(('L', 'R')): 
                continue

            is_china_etf = False
            for kw in china_keywords:
                if kw in row_text:
                    is_china_etf = True
                    break
            if is_china_etf:
                continue

            if href_code not in etf_codes:
                etf_codes.append(href_code)
        return etf_codes
    except Exception as e:
        st.error(f"æŠ“å–æ¸…å–®å¤±æ•—: {e}")
        return []

# --- åŠŸèƒ½ 2ï¼šåˆ†æç¸¾æ•ˆ ---
def get_etf_return(stock_code):
    url = f"https://histock.tw/stock/{stock_code}"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table', class_='tbPerform')
        if not table: return None
            
        target_periods = {'ä¸€å­£': None, 'åŠå¹´': None, 'ä¸€å¹´': None}
        rows = table.find_all('tr')
        for row in rows:
            th = row.find('th')
            td = row.find('td')
            if th and td:
                p_name = th.text.strip()
                if p_name in target_periods:
                    val_span = td.find('span')
                    if val_span:
                        val_str = val_span.text.replace('%', '').replace('+', '').replace(',', '').strip()
                        try:
                            target_periods[p_name] = float(val_str)
                        except: continue

        if all(v is not None for v in target_periods.values()):
            avg_return = sum(target_periods.values()) / 3
            name_tag = soup.find('h3') 
            stock_name = name_tag.text.split('(')[0].strip() if name_tag else "æœªçŸ¥"
            return {
                'ä»£è™Ÿ': stock_code, 'åç¨±': stock_name,
                'ä¸€å­£%': target_periods['ä¸€å­£'], 'åŠå¹´%': target_periods['åŠå¹´'],
                'ä¸€å¹´%': target_periods['ä¸€å¹´'], 'ç¶œåˆå¹³å‡%': round(avg_return, 2)
            }
    except: pass
    return None

# --- ä¸»ç¨‹å¼ä»‹é¢ ---

if st.button('ğŸš€ é–‹å§‹åŸ·è¡Œå…¨å° ETF åˆ†æ'):
    all_etfs = get_etf_list()
    
    if all_etfs:
        total = len(all_etfs)
        st.info(f"æˆåŠŸç¯©é¸å‡º {total} æª” ETFï¼Œé–‹å§‹åˆ†æç¸¾æ•ˆ...")
        
        # å»ºç«‹é€²åº¦æ¢
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results = []
        for i, code in enumerate(all_etfs):
            status_text.text(f"æ­£åœ¨åˆ†æ [{i+1}/{total}]: {code}")
            progress_bar.progress((i + 1) / total)
            
            data = get_etf_return(code)
            if data:
                results.append(data)
            time.sleep(random.uniform(0.1, 0.2)) 

        if results:
            df = pd.DataFrame(results)
            df = df.sort_values(by='ç¶œåˆå¹³å‡%', ascending=False)
            
            st.success("âœ… åˆ†æå®Œæˆï¼")
            
            # é¡¯ç¤ºçµæœè¡¨æ ¼
            st.write("### ç¸¾æ•ˆæ’è¡Œæ¦œ (ä¾ç¶œåˆå¹³å‡æ’åº)")
            st.dataframe(df, use_container_width=True)
            
            # --- ä¸‹è¼‰æŒ‰éˆ• (Excel æ ¼å¼) ---
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ Excel åˆ†æå ±è¡¨",
                data=output.getvalue(),
                file_name="ETF_ç¸¾æ•ˆåˆ†æçµæœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("ç„¡æ³•æŠ“å–åˆ°ä»»ä½•ç¸¾æ•ˆæ•¸æ“šã€‚")
    else:
        st.error("æ¸…å–®æŠ“å–å¤±æ•—æˆ–æ¸…å–®ç‚ºç©ºã€‚")
