import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import io

# --- ç¶²é è¨­å®š ---
st.set_page_config(page_title="å°è‚¡ ETF ç¸¾æ•ˆè‡ªå‹•åˆ†æ", layout="wide")

# --- æ¨™é¡Œèˆ‡æ›´æ–°æŒ‰éˆ•å€å¡Š ---
col1, col2 = st.columns([8, 1])

with col1:
    st.title("ğŸ“Š å°è‚¡ ETF ç¸¾æ•ˆåˆ†ææ’è¡Œæ¦œ")
    st.caption("è³‡æ–™ä¾†æºï¼šHiStock | è‡ªå‹•éæ¿¾ï¼šæ§“æ¡¿ã€åå‘ã€ä¸­åœ‹/æ¸¯è‚¡å¸‚å ´ | æ¨£å¼ï¼šå°è‚¡ç´…æ¼²ç¶ è·Œ")

with col2:
    if st.button('ğŸ”„ æ›´æ–°'):
        st.cache_data.clear()
        st.rerun()

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# --- åŠŸèƒ½ï¼šåˆ†æå–®ä¸€æª” ETF ---
def get_etf_return(stock_code):
    url = f"https://histock.tw/stock/{stock_code}"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        data = {
            'ä»£è™Ÿ': stock_code, 'åç¨±': "æœªçŸ¥", 'å¸‚å ´åˆ¥': "æœªçŸ¥", 
            'ä¸€å­£%': None, 'åŠå¹´%': None, 'ä¸€å¹´%': None, 'ç¶œåˆå¹³å‡%': None
        }

        # æŠ“å–åç¨±
        name_tag = soup.find('h3') 
        if name_tag: data['åç¨±'] = name_tag.text.split('(')[0].strip()

        # æŠ“å–å¸‚å ´åˆ¥
        candidates = soup.find_all(['li', 'td'])
        for tag in candidates:
            text = tag.text.strip()
            if 'å¸‚å ´' in text:
                if 'ä¸Šå¸‚' in text:
                    data['å¸‚å ´åˆ¥'] = 'ä¸Šå¸‚'; break
                elif 'ä¸Šæ«ƒ' in text:
                    data['å¸‚å ´åˆ¥'] = 'ä¸Šæ«ƒ'; break
        if data['å¸‚å ´åˆ¥'] == "æœªçŸ¥":
            if soup.find(string="ä¸Šå¸‚"): data['å¸‚å ´åˆ¥'] = 'ä¸Šå¸‚'
            elif soup.find(string="ä¸Šæ«ƒ"): data['å¸‚å ´åˆ¥'] = 'ä¸Šæ«ƒ'

        # æŠ“å–ç¸¾æ•ˆ
        table = soup.find('table', class_='tbPerform')
        if not table: return None
        
        target_periods = {'ä¸€å­£': 'ä¸€å­£%', 'åŠå¹´': 'åŠå¹´%', 'ä¸€å¹´': 'ä¸€å¹´%'}
        rows = table.find_all('tr')
        periods_data = {}
        for row in rows:
            th = row.find('th')
            td = row.find('td')
            if th and td:
                p_name = th.text.strip()
                if p_name in target_periods:
                    val_span = td.find('span')
                    if val_span:
                        try:
                            val_str = val_span.text.replace('%', '').replace('+', '').replace(',', '').strip()
                            periods_data[p_name] = float(val_str)
                        except: pass
        
        data['ä¸€å­£%'] = periods_data.get('ä¸€å­£')
        data['åŠå¹´%'] = periods_data.get('åŠå¹´')
        data['ä¸€å¹´%'] = periods_data.get('ä¸€å¹´')

        if data['ä¸€å­£%'] is not None and data['åŠå¹´%'] is not None and data['ä¸€å¹´%'] is not None:
            avg = (data['ä¸€å­£%'] + data['åŠå¹´%'] + data['ä¸€å¹´%']) / 3
            data['ç¶œåˆå¹³å‡%'] = round(avg, 2)
            return data
    except: pass
    return None

# --- æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å–èˆ‡åˆ†æ ---
@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨æ›´æ–° ETF è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™...")
def fetch_all_etf_data():
    url = "https://histock.tw/stock/etf.aspx"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        etf_codes = []
        rows = soup.find_all('tr')
        china_keywords = ['ä¸­åœ‹', 'ä¸Šè­‰', 'æ»¬', 'æ·±', 'æ’ç”Ÿ', 'A50', 'é¦™æ¸¯', 'æ¸¯è‚¡']

        for row in rows:
            link = row.find('a', href=True)
            if not link or '/stock/' not in link['href']: continue
            href_code = link['href'].split('/')[-1]
            row_text = row.text.strip()
            
            if len(href_code) < 4 or len(href_code) > 6 or not href_code[0].isdigit(): continue
            if href_code.upper().endswith(('L', 'R')): continue 
            if any(kw in row_text for kw in china_keywords): continue 
            if href_code not in etf_codes: etf_codes.append(href_code)

        results = []
        total = len(etf_codes)
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, code in enumerate(etf_codes):
            status_text.text(f"ğŸš€ æ­£åœ¨åˆ†æ [{i+1}/{total}]: {code} ...")
            progress_bar.progress((i + 1) / total)
            data = get_etf_return(code)
            if data: results.append(data)
            time.sleep(0.05)
        
        status_text.empty()
        progress_bar.empty()
        return pd.DataFrame(results)

    except Exception as e:
        st.error(f"è³‡æ–™æŠ“å–å¤±æ•—: {e}")
        return pd.DataFrame()

# --- â˜… ç¾åŒ–æ¨£å¼å‡½å¼å€ â˜… ---

# 1. æ–‡å­—é¡è‰²ï¼šæ­£ç´…ã€è² ç¶ ã€é›¶é»‘
def style_text_color(val):
    if isinstance(val, (int, float)):
        color = '#d63031' if val > 0 else '#00b894' if val < 0 else 'black'
        return f'color: {color}; font-weight: bold;'
    return ''

# 2. èƒŒæ™¯é¡è‰²ï¼šå‰ä¸‰åé¡¯ç¤ºæ·¡ç´…è‰²
def style_top3_rows(row):
    # æª¢æŸ¥è©²åˆ—çš„ç´¢å¼• (Index) æ˜¯å¦åœ¨ 1, 2, 3 è£¡é¢
    if row.name in [1, 2, 3]:
        return ['background-color: #ffe6e6'] * len(row)
    return [''] * len(row)

# --- ç¶²é åŸ·è¡Œæµç¨‹ ---

df_final = fetch_all_etf_data()

if not df_final.empty:
    cols = ['ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ä¸€å­£%', 'åŠå¹´%', 'ä¸€å¹´%', 'ç¶œåˆå¹³å‡%']
    existing_cols = [c for c in cols if c in df_final.columns]
    
    # æ’åºä¸¦é‡ç½®ç´¢å¼•
    df_sorted = df_final[existing_cols].sort_values(by='ç¶œåˆå¹³å‡%', ascending=False).reset_index(drop=True)
    
    # â˜… é‡é» 1ï¼šå°‡ç´¢å¼•å¾ 0 é–‹å§‹æ”¹æˆå¾ 1 é–‹å§‹
    df_sorted.index = df_sorted.index + 1
    
    st.success(f"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸï¼å…±åˆ†æ {len(df_sorted)} æª” ETFã€‚")
    
    # â˜… é‡é» 2 & 3ï¼šå¥—ç”¨æ¨£å¼
    # é‡å°æ•¸å€¼æ¬„ä½å¥—ç”¨ã€Œç´…æ¼²ç¶ è·Œã€
    styler = df_sorted.style.map(style_text_color, subset=['ä¸€å­£%', 'åŠå¹´%', 'ä¸€å¹´%', 'ç¶œåˆå¹³å‡%'])
    
    # é‡å°æ•´åˆ—å¥—ç”¨ã€Œå‰ä¸‰åèƒŒæ™¯è‰²ã€
    styler = styler.apply(style_top3_rows, axis=1)
    
    # è¨­å®šæ•¸å­—æ ¼å¼ (ä¿ç•™å…©ä½å°æ•¸)
    styler = styler.format("{:.2f}", subset=['ä¸€å­£%', 'åŠå¹´%', 'ä¸€å¹´%', 'ç¶œåˆå¹³å‡%'])
    
    # é¡¯ç¤ºç¾åŒ–å¾Œçš„è¡¨æ ¼
    st.dataframe(styler, use_container_width=True, height=600)
    
    # ä¸‹è¼‰æŒ‰éˆ• (ç¶­æŒä¸è®Šï¼Œä¸‹è¼‰ä¹¾æ·¨çš„ Excel)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_sorted.to_excel(writer, index=True, index_label="æ’å") # ä¸‹è¼‰æ™‚åŒ…å«æ’å
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰ Excel åˆ†æå ±è¡¨",
        data=output.getvalue(),
        file_name="ETF_Analysis_Report.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

else:
    st.warning("ç›®å‰æ²’æœ‰æŠ“åˆ°è³‡æ–™ï¼Œè«‹é»æ“Šå³ä¸Šè§’çš„ã€Œæ›´æ–°ã€æŒ‰éˆ•é‡è©¦ã€‚")
