import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import io

# --- ç¶²é è¨­å®š ---
st.set_page_config(page_title="å°è‚¡ ETF ç¸¾æ•ˆè‡ªå‹•åˆ†æ", layout="wide")

# --- æ¨™é¡Œèˆ‡æ›´æ–°æŒ‰éˆ•å€å¡Š ---
col1, col2 = st.columns([8, 1])

with col1:
    st.title("ğŸ“Š å°è‚¡ ETF ç¸¾æ•ˆåˆ†ææ’è¡Œæ¦œ")
    st.caption("è³‡æ–™ä¾†æºï¼šHiStock | è‡ªå‹•éæ¿¾ï¼šæ§“æ¡¿ã€åå‘ã€ä¸­åœ‹/æ¸¯è‚¡å¸‚å ´")

with col2:
    # é€™è£¡å°±æ˜¯ä½ è¦çš„å¼·åˆ¶æ›´æ–°æŒ‰éˆ•
    if st.button('ğŸ”„ æ›´æ–°'):
        st.cache_data.clear() # æ¸…é™¤å¿«å–
        st.rerun() # é‡æ–°åŸ·è¡Œç¶²é 

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# --- åŠŸèƒ½ï¼šåˆ†æå–®ä¸€æª” ETF ---
def get_etf_return(stock_code):
    url = f"https://histock.tw/stock/{stock_code}"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æ‰¾å°‹ç¸¾æ•ˆè¡¨æ ¼
        table = soup.find('table', class_='tbPerform')
        if not table: return None
        
        target_periods = {'ä¸€å­£': None, 'åŠå¹´': None, 'ä¸€å¹´': None}
        rows = table.find_all('tr')
        
        for row in rows:
            th = row.find('th')
            td = row.find('td')
            if th and td:
                p_name = th.text.strip()
                if p_name in target_periods:
                    val_span = td.find('span')
                    if val_span:
                        val_str = val_span.text.replace('%', '').replace('+', '').replace(',', '').strip()
                        try:
                            target_periods[p_name] = float(val_str)
                        except: continue
                        
        if all(v is not None for v in target_periods.values()):
            avg_return = sum(target_periods.values()) / 3
            # å˜—è©¦æŠ“å–åç¨±
            name_tag = soup.find('h3') 
            stock_name = name_tag.text.split('(')[0].strip() if name_tag else "æœªçŸ¥"
            
            return {
                'ä»£è™Ÿ': stock_code, 
                'åç¨±': stock_name,
                'ä¸€å­£%': target_periods['ä¸€å­£'], 
                'åŠå¹´%': target_periods['åŠå¹´'],
                'ä¸€å¹´%': target_periods['ä¸€å¹´'], 
                'ç¶œåˆå¹³å‡%': round(avg_return, 2)
            }
    except: pass
    return None

# --- â˜… æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å–èˆ‡åˆ†æ (åŠ ä¸Šå¿«å–) ---
# ttl=3600 ä»£è¡¨é€™ä»½è³‡æ–™æœƒè¢«å¿«å– 1 å°æ™‚
@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨æ›´æ–° ETF è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™...")
def fetch_all_etf_data():
    url = "https://histock.tw/stock/etf.aspx"
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        etf_codes = []
        rows = soup.find_all('tr')
        china_keywords = ['ä¸­åœ‹', 'ä¸Šè­‰', 'æ»¬', 'æ·±', 'æ’ç”Ÿ', 'A50', 'é¦™æ¸¯', 'æ¸¯è‚¡']

        # 1. æŠ“å–æ¸…å–®
        for row in rows:
            link = row.find('a', href=True)
            if not link or '/stock/' not in link['href']: continue
            
            href_code = link['href'].split('/')[-1]
            row_text = row.text.strip()
            
            # éæ¿¾é‚è¼¯
            if len(href_code) < 4 or len(href_code) > 6 or not href_code[0].isdigit(): continue
            if href_code.upper().endswith(('L', 'R')): continue # æ’é™¤æ§“æ¡¿/åå‘
            if any(
